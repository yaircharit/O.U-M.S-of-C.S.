# -*- coding: utf-8 -*-
"""Font Recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MyCAVscPITdxxHePPou7eVHP2XftojAj

# Progress
"""

# # from google.colab import drive
# # drive.mount('/content/drive/')

# """To Orgenize the database I seperated each char in every photo (only in the first image for starter."""

# import numpy as np
# import h5py
# db = h5py.File('/content/drive/MyDrive/SynthText.h5')
# validation_number = 0.1*len(db['data'])

# # train =db['data'][:validation_number]
# im_names = list(db['data'].keys())
# im = im_names[0]
# print(im)
# img = db['data'][im][:]
# font = db['data'][im].attrs['font']
# txt = db['data'][im].attrs['txt']
# charBB = db['data'][im].attrs['charBB'].transpose().astype(int)
# wordBB = db['data'][im].attrs['wordBB']

# chars = []
# for i in range(len(charBB)):
#   chars.append({'loc': charBB[i], 'font': font[i]})
  
# # print(chars)

# # for attr in db['data'][im].attrs:
# #   print(attr)
# #   print(db['data'][im].attrs[attr])

# """Getting the image of a letter"""

# import cv2 as cv
# # from google.colab.patches import cv2_imshow

# cv.imshow(img)
# coords = chars[15]['loc'].transpose()
# x_range = (int(min(coords[0])),int(max(coords[0])))
# y_range = (int(min(coords[1])),int(max(coords[1])))
# letter_img = img[y_range[0]:y_range[1],x_range[0]:x_range[1]]

# res = cv.cvtColor(letter_img, cv.COLOR_RGB2GRAY)
# # res = cv.GaussianBlur(res, (3, 3), 0)
# # res = cv.bitwise_not(res)
# print(res)
# temp = []
# s= sum([sum(row)/len(row) for row in res])/len(res)*1.05
# for row in res:
#   row[row <s]=0
# print(chars[15]['font'])
# cv.imshow(res)

"""Now to sum everything so far:
We reorganized the dataset to so that for each image there'll be a list of all letters and its information (location, font, image)

To really start processing the entire DB these tasks needs to be in functions, So i polished their functionalities and improved uppon them while isolating them to stand-alone functions

# Run Starts Here

## Imports
"""
import json
import numpy as np
import h5py
import cv2 as cv
# from google.colab.patches import cv2_imshow
from math import ceil
# from google.colab import drive

"""## Functions"""

def subimage(image, center, wNh, theta):
   ''' 
   Rotates OpenCV image around center with angle theta (in deg)
   then crops the image according to width and height.
   '''

   # Uncomment for theta in radians
   #theta *= 180/np.pi

   width,height = (round(wNh[0]),round(wNh[1]))
   shape = ( image.shape[1], image.shape[0] ) # cv2.warpAffine expects shape in (length, height)

   matrix = cv.getRotationMatrix2D( center=center, angle=theta, scale=1 )
   image = cv.warpAffine( src=image, M=matrix, dsize=shape )
   
   x = int( center[0] - width/2  )
   y = int( center[1] - height/2 )
   
   image = image[ y:y+height, x:x+width ]
   return image

count = 0
def get_letter_image(img,char_coords):
  """
  Gets the specified letter from image and straightens the image
  :param img:   The image to crop letter from
  :char_coords: Letter's BoundBox coordinations
  :return:      A good image of the subimage in char_coords
  """
  rect = cv.minAreaRect(char_coords)
  img_crop = subimage(img,*rect)
  # img_crop = cv.rotate(img_crop, cv.cv2.ROTATE_90_COUNTERCLOCKWISE)
  # if img_crop is not None:
  #   img_crop = cv.cvtColor(img_crop, cv.cv2.COLOR_BGR2GRAY)
  return img_crop

def get_letters_info(img_data):
  """
  gets an image and its data and returns an organized dataset for each letter in the image
  :param img_data:  db['data'][im], contains 'font' and 'charBB'
  :return:          dataset of letters. letter={'font':'...','loc':[coords], 'img': [image]}
  :rtype:           list
  """
  img = img_data[:]
  font = img_data.attrs['font']
  charBB = img_data.attrs['charBB'].transpose().astype(int)
  global count
  chars = []
  for i in range(len(charBB)):
    letter_img = get_letter_image(img,charBB[i])
    if letter_img is not None:
      chars.append({'font': font[i], 'img': letter_img})
    else:
      count += 1
  return chars

"""## Initialize Database and setup data structures

Mount Drive if needed
"""

# drive.mount('/content/drive/')

filename = 'SynthText.h5'
db = h5py.File(filename)
validation_number = 0.1*len(db['data'])
im_names = list(db['data'].keys())

imgs = []
all_chars = []
hf = h5py.File('fonts_data.hdf5','w')
for img_name in im_names:
  print(img_name)
  chars = get_letters_info(db['data'][img_name])
  for i in range(len(chars)):
    ch = chars[i]
    size = ch['img'].shape
    ds = hf.create_dataset(f'{i}_{img_name}',size,dtype='i',data=ch['img'])
    ds.attrs['font'] = ch['font']
  # all_chars += chars
  # imgs.append({'img': db['data'][img_name],'chars':chars})

print(f'{len(all_chars)-count}/28197')

"""## Test dataset"""

# for i in range(15):
cv.imshow('e',all_chars[15]['img'])
cv.waitKey(0)
# print(all_chars[0])